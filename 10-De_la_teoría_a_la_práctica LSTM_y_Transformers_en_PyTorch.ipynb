{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <h1 style=\"color:rgb(228, 12, 33); text-align: center;\">De la teoría a la práctica: LSTM y Transformers en PyTorch</h1>\n\n---\n![imagen.png](https://discuss.pytorch.org/uploads/default/6415da0424dd66f2f5b134709b92baa59e604c55)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color: rgba(100, 108, 116, 0.1); padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n     <p>Bienvenido a este cuaderno de Kaggle, donde profundizaremos en la comprensión e implementación de redes de memoria a corto plazo (LSTM) usando PyTorch, un marco de aprendizaje profundo poderoso. Pero antes de profundizar en las complejidades de LSTM, dediquemos un momento a comprender los conceptos básicos de datos de series temporales, redes neuronales recurrentes (RNN) y LSTM.</p>\n     <h2 style=\"color:rgb(31, 103, 211);\">Datos de series temporales</h2>\n     <p>Los datos de series temporales son una secuencia de puntos de datos numéricos tomados en puntos sucesivos igualmente espaciados en el tiempo. Estos puntos de datos están ordenados y dependen de los puntos de datos anteriores, lo que hace que los datos de series temporales sean los principales candidatos para las predicciones. Los ejemplos de datos de series temporales incluyen precios de acciones, previsiones meteorológicas y datos de ventas, entre muchos otros.</p>\n     <h2 style=\"color:rgb(31, 103, 211);\">Redes neuronales recurrentes (RNN)</h2>\n     <p>Las redes neuronales tradicionales tienen problemas con los datos de series temporales debido a su incapacidad para recordar entradas anteriores en su estado actual. Sin embargo, las redes neuronales recurrentes (RNN) están diseñadas para abordar este problema. Las RNN son una clase de redes neuronales artificiales donde las conexiones entre nodos forman un gráfico dirigido a lo largo de una secuencia temporal. Esto les permite usar su estado interno (memoria) para procesar secuencias de entradas, haciéndolos ideales para datos dependientes del tiempo.</p>\n     <p>Sin embargo, los RNN sufren ciertas limitaciones. Tienen dificultades para manejar las dependencias a largo plazo debido al problema del \"gradiente de fuga\", donde la contribución de la información decae geométricamente con el tiempo, lo que dificulta que la RNN aprenda de las capas anteriores.</p>\n     <h2 style=\"color:rgb(31, 103, 211);\">Memoria a corto plazo (LSTM)</h2>\n     <p>Las redes de memoria a largo plazo o LSTM son un tipo especial de RNN capaz de aprender dependencias a largo plazo. Presentados por Hochreiter y Schmidhuber en 1997, los LSTM tienen un diseño único que ayuda a combatir el problema del gradiente de fuga. Contienen un estado de celda y tres puertas (entrada, olvido y salida) para controlar el flujo de información dentro de la red, lo que les permite recordar u olvidar información durante largos períodos de tiempo.</p>\n     <p>En este cuaderno, exploraremos cómo implementar correctamente LSTM en PyTorch y usarlo para tareas de predicción de series temporales. Cubriremos todo, desde los conceptos básicos de LSTM hasta su implementación, con el objetivo de proporcionar una comprensión integral de esta poderosa arquitectura de red neuronal. ¡Empecemos!</p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"<div style=\"background-color: rgba(100, 108, 116, 0.1); padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n     <h2 style=\"color:rgb(31, 103, 211);\">Comprender la entrada y salida en torch.nn.RNN</h2>\n     <p>En esta sección, profundizaremos en los detalles de los parámetros de entrada y salida del módulo torch.nn.RNN, una implementación de red neuronal recurrente (RNN) integrada en la biblioteca PyTorch. Es crucial comprender estos parámetros para aprovechar al máximo las capacidades de RNN de PyTorch en nuestra implementación de LSTM.</p>\n     <h3 style=\"color:rgb(172, 28, 44);\">Entrada a torch.nn.RNN</h3>\n     <p>El módulo torch.nn.RNN acepta dos entradas principales:</p>\n     <ul>\n         <li><b>entrada</b>: Esto representa la secuencia que se alimenta a la red. El tamaño esperado es (seq_len, lote, input_size). Sin embargo, si se especifica batch_first=True, entonces el tamaño de entrada debe reorganizarse a (batch, seq_len, input_size).</li>\n         <li><b>h_0</b>: representa el estado oculto inicial de la red en el paso de tiempo t=0. Por defecto, si no inicializamos esta capa oculta, PyTorch la inicializará automáticamente con ceros. El tamaño de h_0 debe ser (num_layers * num_directions, batch, input_size), donde num_layers representa la cantidad de RNN apilados y num_directions es igual a 2 para RNN bidireccionales y 1 en caso contrario.</li>\n     </ul>\n     <h3 style=\"color:rgb(172, 28, 44);\">Salida de torch.nn.RNN</h3>\n     <p>El módulo torch.nn.RNN proporciona dos salidas:</p>\n     <ul>\n         <li><b>out</b>: esto representa la salida de la última capa RNN para todos los pasos de tiempo. El tamaño es (seq_len, lote, num_directions * hidden_size). Sin embargo, si se especifica batch_first=True, el tamaño de salida se convierte en (batch, seq_len, num_directions * hidden_size).</li>\n         <li><b>h_n</b>: este es el valor de estado oculto del último paso de tiempo en todas las capas RNN. El tamaño es (num_layers * num_directions, lote, hidden_size). A diferencia de la entrada, el h_n no se ve afectado por batch_first=True.</li>\n     </ul>\n     <p>Para visualizar mejor estas entradas y salidas, consulte el siguiente diagrama. En este caso, asumimos un tamaño de lote de 1. Si bien el diagrama ilustra un LSTM, que tiene dos parámetros ocultos (h, c), tenga en cuenta que RNN y GRU solo tienen h.</p>\n     <p>Al comprender estos parámetros, podemos aprovechar el poder del módulo torch.nn.RNN y crear modelos efectivos para nuestros datos de series temporales utilizando LSTM. Continuemos nuestra exploración de LSTM con PyTorch en las siguientes secciones.</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"![image.png](https://miro.medium.com/max/576/1*tUxl5-C-t3Qumt0cyVhm2g.png)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"TdC\"></a>\n# Tabla de contenido\n- [1. Importaciones](#1)\n- [2. LSTM](#2)\n     - [Muchos a uno] (# 2.1)\n     - [Muchos a muchos] (# 2.2)\n     - [Secuencia de generación de muchos a muchos] (# 2.3)\n- [3. Transformadores] (#3)\n     - [Entrada de enmascaramiento](#3.1)\n     - [fichas SOS y EOS] (#3.2)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# **<div style=\"padding:10px;color:white;display:fill;border-radius:5px;background-color:rgb(31, 103, 211);font-size:120%;font-family: Verdana;\"><center><span> Importaciones </span></center></div>**","metadata":{}},{"cell_type":"code","source":"import torch \nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom tqdm import tqdm \nimport numpy as np \nimport pandas as pd \nimport random\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set_style('white')","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:46:52.039201Z","iopub.execute_input":"2023-05-19T07:46:52.039612Z","iopub.status.idle":"2023-05-19T07:46:57.755607Z","shell.execute_reply.started":"2023-05-19T07:46:52.039575Z","shell.execute_reply":"2023-05-19T07:46:57.754651Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color: #f2f2f2; padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n     <h2 style=\"color:rgb(31, 103, 211);\">Acerca del conjunto de datos</h2>\n     <p>En este cuaderno, utilizaremos una serie de datos de tiempo simple para probar y comprender la aplicación de los modelos LSTM y Transformer. El conjunto de datos elegido es bastante sencillo: un rango de números que comienza en 0 y termina en 1000. Esta simplicidad nos permitirá centrarnos más en el funcionamiento de los modelos LSTM y Transformer, examinando qué tan bien pueden comprender y procesar datos numéricos secuenciales simples. . A través de esto, nuestro objetivo es lograr una comprensión clara de estas poderosas técnicas de aprendizaje profundo.</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# **<div style=\"padding:10px;color:white;display:fill;border-radius:5px;background-color:rgb(31, 103, 211);font-size:120%;font-family:Verdana;\"><center><span> LSTM </span></center></div>**","metadata":{}},{"cell_type":"markdown","source":"<aid=\"2.1\"></a>\n<div style=\"background-color: #f2f2f2; padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n     <h2 style=\"color:rgb(31, 103, 211);\">Comprensión de la arquitectura muchos a uno en LSTM</h2>\n     <p>Las redes de memoria a corto plazo (LSTM), como todas las redes neuronales recurrentes (RNN), son reconocidas por su capacidad para procesar datos secuenciales. Uno de los aspectos clave que los hace flexibles y potentes son los diversos tipos de arquitecturas de entrada y salida que pueden adoptar, una de las cuales es la arquitectura Muchos a Uno.</p>\n     <p>En una arquitectura LSTM de muchos a uno, el modelo acepta una secuencia de entradas en varios pasos de tiempo y produce una sola salida. En cada paso de tiempo, la celda LSTM toma una entrada y el estado oculto de la celda anterior, los procesa y pasa su propio estado oculto a la siguiente celda.</p>\n     <p>A pesar de recibir información en cada paso de tiempo, el LSTM de muchos a uno solo produce su salida final en el último paso de tiempo. Esta característica hace que las redes LSTM de muchos a uno sean particularmente útiles para tareas como el análisis de opiniones, donde un modelo lee una secuencia de palabras (entrada) y genera una única puntuación de opinión, o clasificación de texto, donde un documento se lee secuencialmente y una sola clase se emite la etiqueta.</p>\n     <p>A través del poder de LSTM y la flexibilidad de arquitecturas como Many-to-One, podemos abordar de manera efectiva una amplia gama de problemas basados en secuencias en el mundo del aprendizaje automático y la inteligencia artificial.</p>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"### Crear cargador de datos personalizado [multinúcleo]","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, seq_len=5, max_len=1000):\n        super(CustomDataset).__init__()\n        self.datalist = np.arange(0,max_len)\n        self.data, self.targets = self.timeseries(self.datalist, seq_len)\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def timeseries(self, data, window):\n        temp = []\n        targ = data[window:]\n        for i in range(len(data)-window):\n            temp.append(data[i:i+window])\n\n        return np.array(temp), targ\n    \n    def __getitem__(self, index):\n        x = torch.tensor(self.data[index]).type(torch.Tensor)\n        y = torch.tensor(self.targets[index]).type(torch.Tensor)\n        return x,y\n    \ndataset = CustomDataset(seq_len=5, max_len=1000)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:48:36.369946Z","iopub.execute_input":"2023-05-19T07:48:36.370356Z","iopub.status.idle":"2023-05-19T07:48:36.383860Z","shell.execute_reply.started":"2023-05-19T07:48:36.370316Z","shell.execute_reply":"2023-05-19T07:48:36.382497Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"for x,y in dataset:\n    print(x,y)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:48:40.519656Z","iopub.execute_input":"2023-05-19T07:48:40.520080Z","iopub.status.idle":"2023-05-19T07:48:40.649173Z","shell.execute_reply.started":"2023-05-19T07:48:40.520037Z","shell.execute_reply":"2023-05-19T07:48:40.647881Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"tensor([0., 1., 2., 3., 4.]) tensor(5.)\n","output_type":"stream"}]},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n#collate_fn=custom_collector","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:12.504710Z","iopub.execute_input":"2023-05-19T07:50:12.505623Z","iopub.status.idle":"2023-05-19T07:50:12.511097Z","shell.execute_reply.started":"2023-05-19T07:50:12.505584Z","shell.execute_reply":"2023-05-19T07:50:12.509639Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"for x,y in dataloader:\n    print(x,y)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:50:16.765829Z","iopub.execute_input":"2023-05-19T07:50:16.766196Z","iopub.status.idle":"2023-05-19T07:50:16.910506Z","shell.execute_reply.started":"2023-05-19T07:50:16.766166Z","shell.execute_reply":"2023-05-19T07:50:16.908981Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"tensor([[378., 379., 380., 381., 382.],\n        [949., 950., 951., 952., 953.],\n        [498., 499., 500., 501., 502.],\n        [446., 447., 448., 449., 450.]]) tensor([383., 954., 503., 451.])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<div style=\"background-color: #f2f2f2; padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n<p>Echemos un vistazo más de cerca a nuestro caso de uso específico para la arquitectura LSTM de muchos a uno. En nuestro escenario, estamos alimentando el LSTM con una secuencia de 5 números aleatorios y anticipamos que el modelo predecirá el sexto número de la secuencia. Si bien hemos elegido una serie sencilla de números incrementales para este ejemplo, las posibles aplicaciones de este concepto se extienden mucho más.</p>\n\n<p style=\"color:rgb(172, 28, 44);\">Imagínese que esta secuencia es una serie temporal de datos de precios de acciones, condiciones climáticas o incluso una serie de pasos en una pregunta de razonamiento lógico. La capacidad de predecir el próximo evento en función de una serie de eventos anteriores es un aspecto crítico en muchos campos, incluidas las finanzas, la meteorología y la inteligencia artificial. Al entrenar nuestro modelo LSTM para comprender y predecir estas secuencias, podemos aprovechar la arquitectura LSTM de muchos a uno para resolver problemas complejos en estas áreas y más allá.</p>\n\n</div>","metadata":{}},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.lstm = nn.LSTM(input_size,hidden_size,num_layers,batch_first=True)\n        self.fc = nn.Linear(hidden_size, 1)\n\n    def forward(self, x):\n        # estados ocultos no definidos por lo tanto el valor de h0,c0 == (0,0)\n        out, (hn, cn) = self.lstm(x)\n        \n        # como sugiere el diagrama para tomar la última salida en muchos a uno\n        # imprimir(out.shape)\n        # imprimir(hn.shape)\n        # todo lote, última columna de secuencia, todos los valores ocultos\n        out = out[:, -1, :]\n        out = self.fc(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:54:19.002954Z","iopub.execute_input":"2023-05-19T07:54:19.003347Z","iopub.status.idle":"2023-05-19T07:54:19.011994Z","shell.execute_reply.started":"2023-05-19T07:54:19.003316Z","shell.execute_reply":"2023-05-19T07:54:19.010713Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = RNN(input_size=1, hidden_size=256, num_layers=2)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:56:13.660141Z","iopub.execute_input":"2023-05-19T07:56:13.660742Z","iopub.status.idle":"2023-05-19T07:56:13.683301Z","shell.execute_reply.started":"2023-05-19T07:56:13.660696Z","shell.execute_reply":"2023-05-19T07:56:13.681963Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"t = torch.tensor([11,12,13,14,15]).type(torch.Tensor).view(1,-1,1)\nt.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:56:18.277171Z","iopub.execute_input":"2023-05-19T07:56:18.277595Z","iopub.status.idle":"2023-05-19T07:56:18.288387Z","shell.execute_reply.started":"2023-05-19T07:56:18.277561Z","shell.execute_reply":"2023-05-19T07:56:18.287511Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 5, 1])"},"metadata":{}}]},{"cell_type":"code","source":"model(t)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:56:19.751924Z","iopub.execute_input":"2023-05-19T07:56:19.752302Z","iopub.status.idle":"2023-05-19T07:56:19.894696Z","shell.execute_reply.started":"2023-05-19T07:56:19.752272Z","shell.execute_reply":"2023-05-19T07:56:19.893231Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"tensor([[0.0238]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Training ","metadata":{}},{"cell_type":"code","source":"loss_function = nn.MSELoss()\nlearning_rate = 1e-3\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T07:56:39.611911Z","iopub.execute_input":"2023-05-19T07:56:39.612325Z","iopub.status.idle":"2023-05-19T07:56:39.618931Z","shell.execute_reply.started":"2023-05-19T07:56:39.612292Z","shell.execute_reply":"2023-05-19T07:56:39.617515Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for e in tqdm(range(50)):\n    i = 0\n    for x,y in dataloader:\n        optimizer.zero_grad()\n\n        x = torch.unsqueeze(x, 0).permute(1,2,0)\n        # forward\n        # adelante\n        predictions = model(x)\n\n        loss = loss_function(predictions.view(-1), y)\n        \n        # backward\n        # al revés\n        loss.backward()\n\n        # optimization\n        optimizer.step()\n\n        i+=1\n    if e%5==0:\n        print(loss.detach().numpy())","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-05-19T07:56:41.384589Z","iopub.execute_input":"2023-05-19T07:56:41.385023Z","iopub.status.idle":"2023-05-19T07:59:19.938348Z","shell.execute_reply.started":"2023-05-19T07:56:41.384989Z","shell.execute_reply":"2023-05-19T07:59:19.936721Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"  2%|▏         | 1/50 [00:03<02:46,  3.40s/it]","output_type":"stream"},{"name":"stdout","text":"598389.2\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 6/50 [00:19<02:16,  3.11s/it]","output_type":"stream"},{"name":"stdout","text":"429288.66\n","output_type":"stream"},{"name":"stderr","text":" 22%|██▏       | 11/50 [00:34<02:00,  3.08s/it]","output_type":"stream"},{"name":"stdout","text":"12279.433\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 16/50 [00:50<01:44,  3.07s/it]","output_type":"stream"},{"name":"stdout","text":"25558.162\n","output_type":"stream"},{"name":"stderr","text":" 42%|████▏     | 21/50 [01:06<01:32,  3.19s/it]","output_type":"stream"},{"name":"stdout","text":"1306.0222\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 26/50 [01:22<01:16,  3.19s/it]","output_type":"stream"},{"name":"stdout","text":"1653.8651\n","output_type":"stream"},{"name":"stderr","text":" 62%|██████▏   | 31/50 [01:38<01:00,  3.17s/it]","output_type":"stream"},{"name":"stdout","text":"3010.7336\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 36/50 [01:54<00:44,  3.17s/it]","output_type":"stream"},{"name":"stdout","text":"159.57672\n","output_type":"stream"},{"name":"stderr","text":" 82%|████████▏ | 41/50 [02:09<00:28,  3.14s/it]","output_type":"stream"},{"name":"stdout","text":"32.080643\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 46/50 [02:25<00:12,  3.16s/it]","output_type":"stream"},{"name":"stdout","text":"314.70874\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [02:38<00:00,  3.17s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"input_tensor = torch.tensor([10,11,12,13,14,15,16,17]).type(torch.Tensor).view(1,-1,1)\nmodel(input_tensor)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:11:55.477453Z","iopub.execute_input":"2023-05-19T08:11:55.477908Z","iopub.status.idle":"2023-05-19T08:11:55.492529Z","shell.execute_reply.started":"2023-05-19T08:11:55.477871Z","shell.execute_reply":"2023-05-19T08:11:55.491252Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"tensor([[17.6299]], grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"markdown","source":"<aid=\"2.2\"></a>\n<div style=\"background-color: #f2f2f2; padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n     <h2 style=\"color:rgb(31, 103, 211);\">Comprensión de la arquitectura de muchos a muchos en LSTM</h2>\n    <p>Otra arquitectura crucial en el mundo de las redes de memoria a corto plazo (LSTM), un tipo de red neuronal recurrente (RNN), es la arquitectura de muchos a muchos. Esta arquitectura ofrece una forma versátil de manejar un conjunto diverso de problemas que involucran datos secuenciales.</p>\n     <p>En una arquitectura LSTM de muchos a muchos, el modelo procesa una secuencia de entradas en varios pasos de tiempo y genera una secuencia de salidas. En esta configuración, cada celda LSTM toma una entrada y el estado oculto de la celda anterior en cada paso de tiempo, luego produce una salida junto con su propio estado oculto que pasa a la siguiente celda.</p>\n     <p>A diferencia del LSTM de muchos a uno, el LSTM de muchos a muchos no espera hasta el último paso de tiempo para producir una salida. En su lugar, genera una salida en cada paso de tiempo. Esto hace que las redes LSTM de muchos a muchos sean muy útiles para tareas como la traducción automática, donde una secuencia de palabras en un idioma (entrada) se traduce a una secuencia de palabras en otro idioma (salida).</p>\n     <p>La arquitectura Many-to-Many de LSTM abre una amplia gama de posibilidades, lo que la convierte en una poderosa herramienta en los ámbitos del aprendizaje automático y la inteligencia artificial.</p>\n</div>","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, seq_len=50, future=5,  max_len=1000):\n        super(CustomDataset).__init__()\n        self.datalist = np.arange(0,max_len)\n        self.data, self.targets = self.timeseries(self.datalist, seq_len, future)\n        \n    def __len__(self):\n        #this len will decide the index range in getitem\n        return len(self.targets)\n    \n    def timeseries(self, data, window, future):\n        temp = []\n        targ = []\n        \n        for i in range(len(data)-window):\n            temp.append(data[i:i+window])\n            \n        for i in range(len(data)-window -future):\n            targ.append(data[i+window:i+window+future])\n\n        return np.array(temp), targ\n    \n    def __getitem__(self, index):\n        x = torch.tensor(self.data[index]).type(torch.Tensor)\n        y = torch.tensor(self.targets[index]).type(torch.Tensor)\n        return x,y\n    \ndataset = CustomDataset(seq_len=50, future=5, max_len=1000)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:16:51.900984Z","iopub.execute_input":"2023-05-19T08:16:51.901442Z","iopub.status.idle":"2023-05-19T08:16:51.915948Z","shell.execute_reply.started":"2023-05-19T08:16:51.901408Z","shell.execute_reply":"2023-05-19T08:16:51.914491Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"for x,y in dataset:\n    print(x.shape, y.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:16:55.866754Z","iopub.execute_input":"2023-05-19T08:16:55.867182Z","iopub.status.idle":"2023-05-19T08:16:55.874306Z","shell.execute_reply.started":"2023-05-19T08:16:55.867141Z","shell.execute_reply":"2023-05-19T08:16:55.873044Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"torch.Size([50]) torch.Size([5])\n","output_type":"stream"}]},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)\n#collate_fn=custom_collector","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:16:58.362281Z","iopub.execute_input":"2023-05-19T08:16:58.362722Z","iopub.status.idle":"2023-05-19T08:16:58.368901Z","shell.execute_reply.started":"2023-05-19T08:16:58.362687Z","shell.execute_reply":"2023-05-19T08:16:58.367648Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"for x,y in dataloader:\n    print(x.shape, y.shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:17:01.305818Z","iopub.execute_input":"2023-05-19T08:17:01.306235Z","iopub.status.idle":"2023-05-19T08:17:01.437295Z","shell.execute_reply.started":"2023-05-19T08:17:01.306199Z","shell.execute_reply":"2023-05-19T08:17:01.436107Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"torch.Size([8, 50]) torch.Size([8, 5])\n","output_type":"stream"}]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, future=5):\n        super().__init__()\n        self.future = future\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.lstm = nn.LSTM(input_size,hidden_size,num_layers,batch_first=True)\n        self.fc = nn.Linear(hidden_size, future)\n\n    def forward(self, x):\n        # hidden states not defnined hence the value of h0,c0 == (0,0)\n        out, (hn, cn) = self.lstm(x)\n        \nclass RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, future=5):\n        super().__init__()\n        self.future = future\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.lstm = nn.LSTM(input_size,hidden_size,num_layers,batch_first=True)\n        self.fc = nn.Linear(hidden_size, future)\n\n    def forward(self, x):\n        # hidden states not defnined hence the value of h0,c0 == (0,0)\n        out, (hn, cn) = self.lstm(x)\n        \n        # as the diagram suggest to take the last output in many to one \n        # print(out.shape) \n        # print(hn.shape)\n        # all batch, last column of seq, all hidden values\n        out = out[:, -self.future, :]\n        out = self.fc(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:17:02.994982Z","iopub.execute_input":"2023-05-19T08:17:02.995867Z","iopub.status.idle":"2023-05-19T08:17:03.007039Z","shell.execute_reply.started":"2023-05-19T08:17:02.995820Z","shell.execute_reply":"2023-05-19T08:17:03.005947Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = RNN(input_size=1, hidden_size=256, num_layers=2, future=5)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:17:07.177199Z","iopub.execute_input":"2023-05-19T08:17:07.177649Z","iopub.status.idle":"2023-05-19T08:17:07.196160Z","shell.execute_reply.started":"2023-05-19T08:17:07.177612Z","shell.execute_reply":"2023-05-19T08:17:07.194620Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"d = 45\nt = torch.tensor(np.arange(d,d+50)).type(torch.Tensor).view(1,-1,1)\nt.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:17:09.513937Z","iopub.execute_input":"2023-05-19T08:17:09.514598Z","iopub.status.idle":"2023-05-19T08:17:09.523448Z","shell.execute_reply.started":"2023-05-19T08:17:09.514561Z","shell.execute_reply":"2023-05-19T08:17:09.522100Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 50, 1])"},"metadata":{}}]},{"cell_type":"code","source":"model(t)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:17:14.770723Z","iopub.execute_input":"2023-05-19T08:17:14.771371Z","iopub.status.idle":"2023-05-19T08:17:14.787450Z","shell.execute_reply.started":"2023-05-19T08:17:14.771335Z","shell.execute_reply":"2023-05-19T08:17:14.786162Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.1343, -0.0079,  0.0052, -0.0008, -0.0501]],\n       grad_fn=<AddmmBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"loss_function = nn.MSELoss()\nlearning_rate = 1e-3\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2023-05-19T08:17:23.617509Z","iopub.execute_input":"2023-05-19T08:17:23.617927Z","iopub.status.idle":"2023-05-19T08:17:23.624380Z","shell.execute_reply.started":"2023-05-19T08:17:23.617890Z","shell.execute_reply":"2023-05-19T08:17:23.622805Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"for e in tqdm(range(50)):\n    i = 0\n    avg_loss = []\n    for x,y in dataloader:\n        optimizer.zero_grad()\n\n        x = torch.unsqueeze(x, 0).permute(1,2,0)\n        # forward\n        predictions = model(x)\n        \n        # loss\n        loss = loss_function(predictions, y)\n        \n        # backward\n        loss.backward()\n\n        # optimization\n        optimizer.step()\n        avg_loss.append(loss.detach().numpy())\n\n        i+=1\n    if e%2==0:\n        avg_loss = np.array(avg_loss)\n        print(avg_loss.mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color: #f2f2f2; padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n<p>Después de introducir los 50 términos iniciales de nuestra secuencia en el modelo, comenzamos a observar algunos resultados prometedores. Parece que el modelo está aprendiendo con éxito a reconocer los patrones subyacentes en la secuencia.</p>\n<p>El resultado generado por el modelo parece adherirse a la lógica de la secuencia, lo que sugiere que la arquitectura LSTM está capturando y comprendiendo de manera efectiva las dependencias secuenciales. Esta capacidad de discernir patrones y extrapolarlos es un aspecto poderoso de las redes LSTM, y es gratificante verlo funcionar en nuestro modelo.</p>\n<p>Estos primeros resultados son alentadores e indican que nuestro modelo va por buen camino. A medida que continuamos refinando y entrenando nuestro LSTM, podemos esperar que se vuelva aún más experto en comprender y predecir la secuencia.</p>\n</div>","metadata":{}},{"cell_type":"code","source":"d = random.randint(0,1000)\nt = torch.tensor(np.arange(d,d+50)).type(torch.Tensor).view(1,-1,1)\nr = model(t).view(-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(16,4))\nplt_x = np.arange(0,t.shape[1]+len(r))\nplt_y = np.arange(d,d+50+len(r))\n\nplt_xp = np.arange(t.shape[1], t.shape[1]+len(r))\nplt_yp = r.detach().numpy()\nfor i in range(len(r)):\n    plt.scatter(plt_x, plt_y)\n    plt.scatter(plt_xp, plt_yp)\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<aid=\"2.3\"></a>\n<div style=\"background-color: #f2f2f2; padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n     <h2 style=\"color:rgb(31, 103, 211);\">Comprensión de la generación de secuencias de muchos a muchos con LSTM</h2>\n     <p>Cuando se trabaja con redes de memoria a corto plazo (LSTM), es fundamental comprender cómo se gestiona la generación de secuencias, especialmente en una configuración de muchos a muchos. En una arquitectura de este tipo, la salida de cada celda LSTM se puede utilizar como entrada para una red de realimentación posterior para generar una secuencia de salidas.</p>\n     <p>Consideremos el siguiente bloque de código como ejemplo:</p>\n     <pre style=\"background-color: #e0e0e0; padding: 10px; border-radius: 10px;\">\n         fuera, (hn, cn) = self.lstm(x)\n         res = antorcha.ceros((fuera.forma[0], fuera.forma[1]))\n         para b en el rango (out.shape[0]):\n             alimentar = salir[b, :, :]\n             _out = self.fc(feed).vista(-1)\n             res[b] = _fuera\n     </pre>\n     <p>En este código, <code>self.lstm(x)</code> aplica la capa LSTM a la entrada <code>x</code>, generando una salida <code>out</code> y la final oculto y estados de celda <code>hn</code> y <code>cn</code>. Luego inicializamos un tensor de ceros <code>res</code> del mismo tamaño que <code>out</code> para almacenar nuestros resultados.</p>\n     <p>Luego, para cada secuencia en la salida <code>out</code>, alimentamos la secuencia a través de una capa totalmente conectada <code>self.fc(feed)</code> y remodelamos la salida para que coincida con lo esperado. dimensiones usando <code>.view(-1)</code>. El resultado se almacena en la posición correspondiente en <code>res</code>.</p>\n     <p>Este proceso ejemplifica cómo se puede usar una red LSTM de muchos a muchos para generar una secuencia de salidas, con la capa LSTM y una capa de avance posterior trabajando en conjunto para transformar una secuencia de entradas en una secuencia correspondiente de salidas.</p>\n</div>\n","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, seq_len=50, future=50,  max_len=1000):\n        super(CustomDataset).__init__()\n        self.datalist = np.arange(0,max_len)\n        self.data, self.targets = self.timeseries(self.datalist, seq_len, future)\n        \n    def __len__(self):\n        #this len will decide the index range in getitem\n        return len(self.targets)\n    \n    def timeseries(self, data, window, future):\n        temp = []\n        targ = []\n        \n        for i in range(len(data)-window):\n            temp.append(data[i:i+window])\n            \n        for i in range(len(data)-window -future):\n            targ.append(data[i+future:i+window+future])\n\n        return np.array(temp), targ\n    \n    def __getitem__(self, index):\n        x = torch.tensor(self.data[index]).type(torch.Tensor)\n        y = torch.tensor(self.targets[index]).type(torch.Tensor)\n        return x,y\n    \ndataset = CustomDataset(seq_len=50, future=5, max_len=1000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in dataset:\n    print(x.shape, y.shape)\n    break","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)\n#collate_fn=custom_collector","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, future=5):\n        super().__init__()\n        self.future = future\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        \n        self.lstm = nn.LSTM(input_size,hidden_size,num_layers,batch_first=True)\n        self.fc = nn.Linear(hidden_size, 1)\n\n    def forward(self, x):\n        # hidden states not defnined hence the value of h0,c0 == (0,0)\n        out, (hn, cn) = self.lstm(x)\n        \n        # as the diagram suggest to take the last output in many to one \n        # print(out.shape)\n        # print(hn.shape)\n        # all batch, last column of seq, all hidden values\n        res = torch.zeros((out.shape[0], out.shape[1]))\n        for b in range(out.shape[0]):\n            feed = out[b, :, :]\n            _out = self.fc(feed).view(-1)\n            res[b] = _out\n        \n        return res","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = RNN(input_size=1, hidden_size=256, num_layers=2, future=5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = torch.tensor(np.arange(d,d+50)).type(torch.Tensor).view(1,-1,1)\nr = model(t).view(-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_function = nn.MSELoss()\nlearning_rate = 1e-3\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for e in tqdm(range(100)):\n    i = 0\n    avg_loss = []\n    for x,y in dataloader:\n        optimizer.zero_grad()\n\n        x = torch.unsqueeze(x, 0).permute(1,2,0)\n        # forward\n        predictions = model(x)\n        \n        # loss\n        loss = loss_function(predictions, y)\n        \n        # backward\n        loss.backward()\n\n        # optimization\n        optimizer.step()\n        avg_loss.append(loss.detach().numpy())\n\n        i+=1\n        \n    if e%5==0:\n        avg_loss = np.array(avg_loss)\n        print(avg_loss.mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = random.randint(0,1000)\nt = torch.tensor(np.arange(d,d+50)).type(torch.Tensor).view(1,-1,1)\nr = model(t).view(-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(16,4))\nplt_x = np.arange(0,t.shape[1])\nplt_y = np.arange(d,d+50)\n\nplt_xp = np.arange(5, t.shape[1]+5)\nplt_yp = r.detach().numpy()\nfor i in range(len(r)):\n    plt.scatter(plt_x, plt_y, label=\"real\")\n    plt.scatter(plt_xp, plt_yp, label=\"predicted\")\n    \nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"2\"></a>\n# **<div style=\"padding:10px;color:white;display:fill;border-radius:5px;background-color:rgb(31, 103, 211);font-size:120%;font-family:Verdana;\"><center><span> Transformers </span></center></div>**","metadata":{}},{"cell_type":"markdown","source":"<aid=\"2.3\"></a>\n<div style=\"background-color: #f2f2f2; padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n     <p style=\"color:rgb(172, 28, 44);\">Los transformadores, un gran avance en el campo del procesamiento del lenguaje natural, también adoptan varios tipos de arquitecturas de entrada y salida, incluida la configuración de muchos a muchos. En este contexto, los transformadores aportan un enfoque único a la mesa, que contrasta con los métodos utilizados en las redes neuronales recurrentes (RNN) tradicionales como LSTM.</p>\n     <p>En una arquitectura de transformador de muchos a muchos, el modelo acepta una secuencia de entradas y devuelve una secuencia de salidas. Sin embargo, a diferencia de los RNN, que procesan secuencias en pasos de tiempo, los transformadores procesan todas las entradas simultáneamente. Esto es posible gracias al mecanismo de atención, que permite que el modelo se centre en diferentes partes de la secuencia de entrada para cada salida, esencialmente creando un \"atajo\" entre cada entrada y salida.</p>\n     <p>Esta arquitectura es especialmente útil en tareas como la traducción automática, donde el modelo necesita comprender el contexto de la oración completa para traducirla con precisión. Del mismo modo, se puede utilizar en tareas como resúmenes de texto o respuesta a preguntas, donde comprender todo el contexto a la vez puede conducir a mejores resultados.</p>\n     <p>La arquitectura Many-to-Many de Transformers, combinada con su mecanismo de atención, ofrece un enfoque innovador para abordar tareas secuenciales, lo que convierte a Transformers en una poderosa herramienta en el campo del aprendizaje automático y la inteligencia artificial.</p>\n</div>","metadata":{}},{"cell_type":"markdown","source":"\n![image.png](https://images.deepai.org/converted-papers/2001.08317/x1.png)","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, seq_len=50, future=50,  max_len=1000):\n        super(CustomDataset).__init__()\n        \n        self.vocab = {'SOS':1001, 'EOS':1002}\n        self.datalist = np.arange(0,max_len)\n        self.data, self.targets = self.timeseries(self.datalist, seq_len, future)\n        \n    def __len__(self):\n        #this len will decide the index range in getitem\n        return len(self.targets)\n    \n    def timeseries(self, data, window, future):\n        temp = []\n        targ = []\n        \n        for i in range(len(data)-window):\n            temp.append(data[i:i+window])\n            \n        for i in range(len(data)-window -future):\n            targ.append(data[i+future:i+window+future])\n\n        return np.array(temp), targ\n    \n    def __getitem__(self, index):\n        x = torch.tensor(self.data[index]).type(torch.Tensor)\n        x = torch.cat((torch.tensor([self.vocab['SOS']]), x, torch.tensor([self.vocab['EOS']]))).type(torch.LongTensor)\n        \n        y = torch.tensor(self.targets[index]).type(torch.Tensor)\n        y = torch.cat((torch.tensor([self.vocab['SOS']]), y, torch.tensor([self.vocab['EOS']]))).type(torch.LongTensor)\n        \n        return x,y\n    \ndataset = CustomDataset(seq_len=48, future=5, max_len=1000)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in dataset:\n    print(x)\n    print(y)\n    break","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=4)\n#collate_fn=custom_collector","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x, y in dataloader:\n    print(x.shape)\n    print(y.shape)\n    break","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3.1\"></a>\n<div style=\"background-color: #f2f2f2; padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n     <h3 style=\"color:rgb(172, 28, 44);\">El poder del enmascaramiento y la eficiencia en los transformadores</h3>\n     <p>Una de las características notables de Transformers es el uso de máscaras durante el proceso de entrenamiento. El enmascaramiento es un aspecto esencial de la arquitectura de Transformer que evita que el modelo vea tokens futuros en la secuencia de entrada durante el entrenamiento, preservando así la naturaleza secuencial del lenguaje.</p>\n     <p>En una tarea como la traducción de idiomas, donde la secuencia de entrada se introduce en el modelo de una sola vez, es fundamental que la predicción de cada palabra no dependa de las palabras que le siguen en la secuencia. Esto se logra aplicando una máscara a la entrada que efectivamente oculta las palabras futuras del modelo durante la fase de entrenamiento.</p>\n     <p>El enmascaramiento no solo mantiene la integridad secuencial del lenguaje, sino que también permite que los Transformers entrenen de manera más eficiente que sus contrapartes RNN, como LSTM. A diferencia de los RNN, que procesan secuencias paso a paso y, por lo tanto, requieren tiempos de entrenamiento más largos para secuencias largas, los transformadores pueden procesar todos los tokens de la secuencia simultáneamente, gracias a su mecanismo de atención. Este procesamiento paralelo acelera significativamente el proceso de entrenamiento y permite que el modelo maneje secuencias más largas de manera más efectiva.</p>\n     <p>Por lo tanto, mediante el uso de enmascaramiento y su arquitectura única, los Transformers logran superar algunas de las limitaciones de los RNN tradicionales, ofreciendo un enfoque más eficiente y eficaz para las tareas basadas en secuencias en el aprendizaje automático y la inteligencia artificial.</p>\n</div>","metadata":{}},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, num_tokens, dim_model, num_heads, num_layers, input_seq):\n        super().__init__()\n        self.input_seq = input_seq\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(num_tokens, dim_model)\n        self.transformer = nn.Transformer(d_model=dim_model, nhead=num_heads,  \n                                          num_encoder_layers=3, num_decoder_layers=3, \n                                          dim_feedforward=256, batch_first=True)\n        \n        self.fc = nn.Linear(dim_model, num_tokens)\n\n    def forward(self, src, tgt, tf=True):\n        mask = self.get_mask(tgt.shape[1], teacher_force=tf)\n        src = self.embedding(src) \n        tgt = self.embedding(tgt)\n        \n        out = self.transformer(src, tgt, tgt_mask=mask)\n        feed = self.fc(out)\n        feed = torch.squeeze(feed,2)\n        \n        return feed\n            \n            \n    def get_mask(self, size, teacher_force=True):\n        if teacher_force:\n            mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n            mask = mask.float()\n            mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n            mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n\n            # EX for size=5:\n            # [[0., -inf, -inf, -inf, -inf],\n            #  [0.,   0., -inf, -inf, -inf],\n            #  [0.,   0.,   0., -inf, -inf],\n            #  [0.,   0.,   0.,   0., -inf],\n            #  [0.,   0.,   0.,   0.,   0.]]\n\n            return mask\n        else:\n            mask = torch.tril(torch.zeros(size, size) == 1) # Lower triangular matrix\n            mask = mask.float()\n            mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n            mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n\n            return mask","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Transformer(num_tokens=1000+3, dim_model=32, num_heads=2, num_layers=2, input_seq=50)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x.shape, y.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model(x, y).shape ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = model(x,y)\nt.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t.permute(0,2,1).shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_function = nn.CrossEntropyLoss()\nlearning_rate = 1e-3\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for e in tqdm(range(25)):\n    i = 0\n    avg_loss = []\n    for x,y in dataloader:\n        optimizer.zero_grad()\n        \n        #one step behind input and output // Like language modeling \n        y_input = y[:, :-1]         # from starting to -1 position\n        y_expected = y[:, 1:]       # from 1st position to last \n        # this is done so that in prediction we see a start of token \n        \n        # forward\n        predictions = model(x, y_input)\n        pred = predictions.permute(0, 2, 1)\n        \n        # loss\n        loss = loss_function(pred, y_expected)\n        \n        # backward\n        loss.backward()\n\n        # optimization\n        optimizer.step()\n        avg_loss.append(loss.detach().numpy())\n\n        i+=1\n        \n    if e%5==0:\n        avg_loss = np.array(avg_loss)\n        print(avg_loss.mean())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.squeeze(predictions.topk(1).indices, 2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_expected ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.argmax(pred, dim=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"3.2\"></a>\n<div style=\"background-color: #f2f2f2; padding: 20px; border-radius: 10px; color: #333; font-family: Arial, sans-serif;\">\n     <h3 style=\"color:rgb(172, 28, 44);\">El papel de los tokens SOS y EOS en los transformadores</h3>\n     <p>En el dominio del procesamiento del lenguaje natural, especialmente cuando se trabaja con modelos de Transformer, los tokens especiales como el inicio de oración (SOS) y el final de oración (EOS) desempeñan un papel fundamental. Estos tokens brindan pistas valiosas sobre los límites de las oraciones, lo que facilita la comprensión de la estructura del lenguaje por parte del modelo.</p>\n     <p>El token SOS se agrega al comienzo de cada oración, marcando su inicio. De manera similar, el token EOS se agrega al final de cada oración para indicar su conclusión. Estos tokens sirven como marcadores consistentes que ayudan al modelo a identificar y procesar oraciones como unidades distintas dentro de cuerpos de texto más grandes.</p>\n     <p>Además, en el contexto de las tareas de generación de secuencias, estos tokens juegan un papel esencial para determinar cuándo comenzar y finalizar el proceso de generación. Por ejemplo, durante la generación de texto, un token EOS le indica al modelo que debe dejar de generar más tokens.</p>\n     <p>Por lo tanto, los tokens SOS y EOS son más que simples marcadores; son componentes integrales en el diseño y funcionamiento de los modelos de Transformer, lo que contribuye significativamente a su capacidad para comprender y generar lenguaje humano de manera efectiva.</p>\n</div>","metadata":{}},{"cell_type":"code","source":"def predict(model, input_sequence, max_length=50, SOS_token=1000+1, EOS_token=1000+2):\n    model.eval()\n    \n    input_sequence = torch.tensor(input_sequence)\n    input_sequence = torch.cat((torch.tensor([SOS_token]), input_sequence, torch.tensor([EOS_token]))).type(torch.LongTensor) \n    input_sequence = torch.unsqueeze(input_sequence,0)\n    \n    y_input = torch.tensor([1001], dtype=torch.long)\n    y_input = torch.unsqueeze(y_input,0)\n\n    for _ in range(max_length):\n        \n        predictions = model(input_sequence, y_input)\n        \n        top = predictions.topk(1).indices\n        top = torch.squeeze(top, 2)\n        \n        next_item = torch.unsqueeze(top[:,-1],0)\n        y_input = torch.cat((y_input, next_item), dim=1)\n        mask = model.get_mask(y_input.shape[1])\n        if next_item == EOS_token:\n            break\n\n    return y_input.view(-1).tolist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = random.randint(0,900)\nt = torch.tensor(np.arange(d,d+48)).type(torch.Tensor)\ninput_sequence = t\nprint(t)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r=predict(model, input_sequence)\nprint(r)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(16,4))\n\nplt_x = np.arange(0,t.shape[0])\nplt_y = t\n\nplt_xp = np.arange(5, t.shape[0]+5)\nplt_yp = r[1:-2]\n\nplt.scatter(plt_x, plt_y, s=14, color='r', label=\"real\")\nplt.scatter(plt_xp, plt_yp, s=7, color='b', label=\"predicted\")\n    \nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}