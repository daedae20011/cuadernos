{"metadata":{"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction to CNN Keras - Acc 0.997 (top 8%) \n### **Yassine Ghouzam, PhD**\n#### 18/07/2017\n\n* **1. Introduction**\n* **2. Data preparation**\n    * 2.1 Load data\n    * 2.2 Check for null and missing values\n    * 2.3 Normalization\n    * 2.4 Reshape\n    * 2.5 Label encoding\n    * 2.6 Split training and valdiation set\n* **3. CNN**\n    * 3.1 Define the model\n    * 3.2 Set the optimizer and annealer\n    * 3.3 Data augmentation\n* **4. Evaluate the model**\n    * 4.1 Training and validation curves\n    * 4.2 Confusion matrix\n* **5. Prediction and submition**\n    * 5.1 Predict and Submit results","metadata":{"_uuid":"f2156d1dd26a1243e18512002e10872c5bd7271e","_cell_guid":"d4c08f48-fe23-4ddb-ac46-d97f05397514"}},{"cell_type":"markdown","source":"# 1. Introducción\n\nEsta es una red neuronal convolucional secuencial de 5 capas para el reconocimiento de dígitos entrenada en el conjunto de datos MNIST. Elegí construirlo con la API de keras (backend de Tensorflow), que es muy intuitivo. En primer lugar, prepararé los datos (imágenes de dígitos escritos a mano) y luego me centraré en el modelado y la evaluación de CNN.\n\nLogré un 99.671% de precisión con esta CNN entrenada en 2h30 en una sola CPU (i5 2500k). Para aquellos que tienen capacidades de GPU >= 3.0 (desde GTX 650 hasta GPU recientes), pueden usar tensorflow-gpu con keras. ¡El cálculo será mucho más rápido!\n\n**Por razones de cálculo, configuré el número de pasos (épocas) en 2, si desea lograr más del 99 % de precisión, configúrelo en 30.**\n\nEste Cuaderno consta de tres partes principales:\n\n* La preparación de datos\n* El modelado y evaluación de CNN\n* La predicción y presentación de resultados.\n\n\n\n\n<img src=\"http://img1.imagilive.com/0717/mnist-sample.png\" ></img>","metadata":{"_uuid":"e9aff3cf1bb8daa73bec67b970d12195677679f3","_cell_guid":"eb88b372-a6e5-40c8-a1c6-c03799165490"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\n%matplotlib inline\n\nnp.random.seed(2)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\n\n\nsns.set(style='white', context='notebook', palette='deep')","metadata":{"_execution_state":"idle","_uuid":"72334cb006d02a4bcfc2a2fe622524eba824c6f8","_cell_guid":"f67b9393-8ea1-4e23-b856-2ce149cfe421","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 2. Preparación de datos\n## 2.1 Cargar datos","metadata":{"_execution_state":"idle","_uuid":"86061d98eccaa02efe0dab0fa3884e71fcf4c310","_cell_guid":"6d2fb3e6-ab71-4974-b5a2-4af1ebdb99f4"}},{"cell_type":"code","source":"# Cargar los datos\ntrain = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")","metadata":{"_execution_state":"idle","_uuid":"84bbd5ab8d7895bd430d5ecfe2f7ddf77baa7b74","_cell_guid":"5e51d00e-62fd-4141-bf73-50ac4f2da7d0","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"Y_train = train[\"label\"]\n\n# eliminar la columna 'etiqueta'\nX_train = train.drop(labels = [\"label\"],axis = 1) \n\n# libera algo de espacio\ndel train \n\ng = sns.countplot(Y_train)\n\nY_train.value_counts()","metadata":{"_execution_state":"idle","_uuid":"1213b979d5ed3e0d13824d17d694c79d2ece92fa","_cell_guid":"86570a36-5c20-460a-9dfd-2070548532a7","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"Tenemos conteos similares para los 10 dígitos.","metadata":{"_uuid":"b7b1b1d36243c885e57374c8b60c5a7e10abe922","_cell_guid":"5aea4062-1790-4987-b739-c4bebd79030f"}},{"cell_type":"markdown","source":"## 2.2 Comprobar valores nulos y faltantes","metadata":{"_uuid":"5d77934302869925c19128c77e247b3c8ca84d71","_cell_guid":"5b7d4b66-a140-4fcc-a889-bcef007c880a"}},{"cell_type":"code","source":"# Revisa los datos\nX_train.isnull().any().describe()","metadata":{"_execution_state":"idle","_uuid":"cdf27c27e2a5b15e6d7bfc70de7a18c08f3feb7a","_cell_guid":"ececaa00-2ae3-4d13-b631-438df085b030","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test.isnull().any().describe()","metadata":{"_execution_state":"idle","_uuid":"a0089bb7ec9aec76373db475399aea24699ae989","_cell_guid":"92572e80-8543-4e72-8767-5c9be8381b04","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Compruebo si hay imágenes dañadas (faltan valores en el interior).\n\nNo faltan valores en el conjunto de datos de tren y prueba. Para que podamos seguir adelante con seguridad.","metadata":{"_uuid":"c0bee59691c2df0b275c78e38e7f9907d02ac038","_cell_guid":"09d04cae-4245-4659-85dd-ef48531da295"}},{"cell_type":"markdown","source":"## 2.3 Normalización\nRealizamos una normalización en escala de grises para reducir el efecto de las diferencias de iluminación.\n\nAdemás, la CNN converge más rápido en [0..1] datos que en [0..255].","metadata":{"_uuid":"0ecf4b52510ab7957d0d4eb646c0aa1ba5986273","_cell_guid":"159d5854-437a-4d0f-bc1e-fc3f7e43d178"}},{"cell_type":"code","source":"# Normalizar los datos\nX_train = X_train / 255.0\ntest = test / 255.0","metadata":{"_execution_state":"idle","_uuid":"b5d4f8fcf2a967e2c7d57daedf95aa8c5ab7f8cb","_cell_guid":"cdc4340b-6e24-4e12-be99-ac806098ff17","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## 2.3 Reshape","metadata":{"_uuid":"a66741bf1ac597094f3a3166877008feef27c519","_cell_guid":"7413df94-bcb9-4f75-b174-c127d4445766"}},{"cell_type":"code","source":"# Reformar la imagen a 3 dimensiones (height = 28px, width = 28px , canal = 1)\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","metadata":{"_execution_state":"idle","_uuid":"f0a6ad80dab8e0f2c2e46165ccd9cd82dd162bc3","_cell_guid":"34b6a5f7-8fd2-4387-8ef4-c9dc19584fed"},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Las imágenes de entrenamiento y prueba (28 px x 28 px) se han almacenado en pandas. Dataframe como vectores 1D de 784 valores. Reformamos todos los datos a matrices 3D de 28x28x1.\n\nKeras requiere una dimensión extra al final que corresponde a los canales. Las imágenes MNIST están en escala de grises, por lo que solo usan un canal. Para imágenes RGB, hay 3 canales, habríamos remodelado vectores de 784 px a matrices 3D de 28x28x3.","metadata":{"_uuid":"f4fb5553e188d9956f5d8b3a5d275ab00ea667ce","_cell_guid":"8decd1ce-7b7e-431d-8458-eaca18e0e1f7"}},{"cell_type":"markdown","source":"## 2.5 Label encoding","metadata":{"_uuid":"39b7a31e843bac6b705461bcce89da216b91799e","_cell_guid":"bdb422e2-bdec-444f-97a5-283a1e54bf2c"}},{"cell_type":"code","source":"# Codificar etiquetas en un vector activo (por ejemplo: 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_train = to_categorical(Y_train, num_classes = 10)","metadata":{"_execution_state":"idle","_uuid":"cabefd1478d5c1bdfe57fd6a34395340916a854c","_cell_guid":"4b7f3e78-44dc-4561-b1f0-9429ee024cf4","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Las etiquetas son números de 10 dígitos del 0 al 9. Necesitamos codificar las etiquetas en un vector activo (por ejemplo: 2 -> [0,0,1,0,0,0,0,0,0,0]).","metadata":{"_uuid":"dcfb688587dfc6feafd27442a3505e35dc01b82d","_cell_guid":"ae068bd8-b12e-4768-8a7e-0fc865dd7562"}},{"cell_type":"markdown","source":"## 2.6 Conjunto dividido de entrenamiento y validación","metadata":{"_uuid":"d8abbbf31483b94e1b29d07c4c8253d1311648a7","_cell_guid":"32152fc3-a570-4d64-8a7d-6c689a4acd33"}},{"cell_type":"code","source":"# Establecer la semilla aleatoria\nrandom_seed = 2","metadata":{"_execution_state":"idle","_uuid":"6e51c925c6e0f1b936679c9649fef345c853555f","_cell_guid":"3a698301-9759-4279-ae48-fd980f89ea53"},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Dividir el tren y el conjunto de validación para el ajuste\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)","metadata":{"_execution_state":"idle","_uuid":"b779ac76d8317647db92d5a88b4098d212d72884","_cell_guid":"dcd25ebb-d845-4d32-9867-082e352b1396","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"I choosed to split the train set in two parts : a small fraction (10%) became the validation set which the model is evaluated and the rest (90%) is used to train the model.\n\nSince we have 42 000 training images of balanced labels (see 2.1 Load data), a random split of the train set doesn't cause some labels to be over represented in the validation set. Be carefull with some unbalanced dataset a simple random split could cause inaccurate evaluation during the validation. \n\nTo avoid that, you could use stratify = True option in train_test_split function (**Only for >=0.17 sklearn versions**).","metadata":{"_uuid":"72ed54a305eebf80e8b8b0f7eabde1332a5a85a3","_cell_guid":"3c99964f-4500-4f1c-947d-c67e644e34db"}},{"cell_type":"markdown","source":"We can get a better sense for one of these examples by visualising the image and looking at the label.","metadata":{"_uuid":"60eed15ec5bc0d354385301789ecb8538fc02267","_cell_guid":"adbeacf0-0dc0-4675-b2df-9c9663750f32"}},{"cell_type":"code","source":"# Algunos ejemplos\ng = plt.imshow(X_train[0][:,:,0])","metadata":{"_execution_state":"idle","_uuid":"e0dae8943d3d35f075dba3d7ba31bde1d4bf2ff4","_cell_guid":"5f76131b-4ba0-45f1-a98c-bd4e7d561793","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# 3. CNN\n## 3.1 Definir el modelo","metadata":{"_uuid":"5fa18b37a9acd9e098bac1d12264b0dd4310fdd3","_cell_guid":"d5265777-aeb3-449d-b171-d88cad74c0a4"}},{"cell_type":"markdown","source":"Usé la API secuencial de Keras, donde solo tiene que agregar una capa a la vez, comenzando desde la entrada.\n​\nLa primera es la capa convolucional (Conv2D). Es como un conjunto de filtros que se pueden aprender. Elegí configurar 32 filtros para las dos primeras capas conv2D y 64 filtros para las dos últimas. Cada filtro transforma una parte de la imagen (definida por el tamaño del núcleo) utilizando el filtro del núcleo. La matriz de filtro kernel se aplica a toda la imagen. Los filtros pueden verse como una transformación de la imagen.\n​\nLa CNN puede aislar características que son útiles en todas partes a partir de estas imágenes transformadas (mapas de características).\n​\nLa segunda capa importante en CNN es la capa de agrupación (MaxPool2D). Esta capa simplemente actúa como un filtro de reducción de resolución. Mira los 2 píxeles vecinos y elige el valor máximo. Estos se utilizan para reducir el costo computacional y, en cierta medida, también reducen el sobreajuste. Tenemos que elegir el tamaño de agrupación (es decir, el tamaño del área agrupada cada vez) cuanto más alta sea la dimensión de agrupación, más importante será la reducción de resolución.\n​\nAl combinar capas convolucionales y de agrupación, CNN puede combinar características locales y aprender más características globales de la imagen.\n​\nDropout es un método de regularización, donde una proporción de nodos en la capa se ignora aleatoriamente (estableciendo sus pesos en cero) para cada muestra de entrenamiento. Esto elimina aleatoriamente una parte de la red y obliga a la red a aprender funciones de forma distribuida. Esta técnica también mejora la generalización y reduce el sobreajuste.\n​\n'relu' es el rectificador (función de activación max(0,x). La función de activación del rectificador se usa para agregar no linealidad a la red.\n​\nLa capa Flatten se usa para convertir los mapas de características finales en un solo vector 1D. Este paso de aplanamiento es necesario para poder utilizar capas totalmente conectadas después de algunas capas convolucionales/maxpool. Combina todas las características locales encontradas de las capas convolucionales anteriores.\n​\nAl final, utilicé las funciones en dos capas completamente conectadas (Densas), que es solo un clasificador artificial de redes neuronales (ANN). En la última capa (Dense (10, activación = \"softmax\")) la red genera la distribución de probabilidad de cada clase.","metadata":{"_uuid":"7697570491420f957f6e4d3569d51410b5277250","_cell_guid":"504fa00e-148c-4364-9b68-218b3aaedfdb"}},{"cell_type":"code","source":"# Establecer el modelo CNN\n# mi arquitectura CNN está en -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (28,28,1)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\"))","metadata":{"_execution_state":"idle","_uuid":"f7991ef6871a26f9fa57acdcd460a69bab53e804","_cell_guid":"1e0f3f88-2ad7-459e-8e02-aecc5f3511ae","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Configurar el optimizador y recocido\n\nUna vez que nuestras capas se agregan al modelo, debemos configurar una función de puntuación, una función de pérdida y un algoritmo de optimización.\n\nDefinimos la función de pérdida para medir qué tan mal funciona nuestro modelo en imágenes con etiquetas conocidas. Es la tasa de error entre las etiquetas observadas y las predichas. Usamos un formulario específico para clasificaciones categóricas (> 2 clases) llamado \"categorical_crossentropy\".\n\nLa función más importante es el optimizador. Esta función mejorará iterativamente los parámetros (filtros de valores del núcleo, pesos y sesgo de las neuronas...) para minimizar la pérdida.\n\nElegí RMSprop (con valores predeterminados), es un optimizador muy efectivo. La actualización de RMSProp ajusta el método Adagrad de una manera muy simple en un intento de reducir su tasa de aprendizaje agresiva y monótonamente decreciente.\nTambién podríamos haber usado el optimizador Stochastic Gradient Descent ('sgd'), pero es más lento que RMSprop.\n\nLa función métrica \"precisión\" se utiliza para evaluar el rendimiento de nuestro modelo.\nEsta función de métrica es similar a la función de pérdida, excepto que los resultados de la evaluación de la métrica no se utilizan al entrenar el modelo (solo para la evaluación).","metadata":{"_uuid":"7065512cf892ba49f0c06e239e3a20ff13667ef2","_cell_guid":"0e26b6a3-ef9d-4ae5-9d79-d5e4b073251a"}},{"cell_type":"code","source":"# Definir el optimizador\noptimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)","metadata":{"_execution_state":"idle","_uuid":"420c704367b397b8255fefe9d882b35ac8929b95","_cell_guid":"a4c55409-6a65-400a-b5e8-a1dc535429c0","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Compilar el modelo\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"_execution_state":"idle","_uuid":"b4c0288622227a3cd05479aa765e324dbb852f34","_cell_guid":"0bd89b79-1a74-40da-af9a-7a76a8b96ff2","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"f4d89b29d55b328e8c446880505c54e674eeec38","_cell_guid":"6bc49be3-11e5-48fb-b70f-601aec0f0c86"}},{"cell_type":"markdown","source":"Para hacer que el optimizador converja más rápido y más cerca del mínimo global de la función de pérdida, utilicé un método de recocido de la tasa de aprendizaje (LR).\n\nEl LR es el paso por el cual el optimizador recorre el 'panorama de pérdidas'. Cuanto mayor sea el LR, mayores serán los pasos y más rápida la convergencia. Sin embargo, el muestreo es muy pobre con un LR alto y el optimizador probablemente podría caer en un mínimo local.\n\nEs mejor tener una tasa de aprendizaje decreciente durante el entrenamiento para alcanzar eficientemente el mínimo global de la función de pérdida.\n\nPara mantener la ventaja del tiempo de cálculo rápido con un LR alto, reduje el LR dinámicamente cada X pasos (épocas) dependiendo si es necesario (cuando no se mejora la precisión).\n\nCon la función ReduceLROnPlateau de Keras.callbacks, elijo reducir el LR a la mitad si la precisión no mejora después de 3 épocas.","metadata":{"_uuid":"bb90d48f4426d1baeb0404f2431e04e3cade59df","_cell_guid":"35b826b6-c516-47d0-8469-f8d04a102118"}},{"cell_type":"code","source":"# Establecer un recocido de tasa de aprendizaje\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)","metadata":{"_execution_state":"idle","_uuid":"c4a5b4e462ec5362c47eef4fcc7956fd4e203307","_cell_guid":"b5987a18-6bbe-42a2-9d31-333ebc4f7af1","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"epochs = 1 # Gire las épocas a 30 para obtener una precisión de 0.9967\nbatch_size = 86","metadata":{"_execution_state":"idle","_uuid":"26b0647c46efdb6b1096cf7335a7bf2a3417543a","_cell_guid":"970db455-b393-4b25-806d-92c6766c12c0","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"_uuid":"f24df64b223e0177c94025b6767ab19b722c5386","_cell_guid":"241a0f4f-13f5-4b13-be1e-4e3e4a714c06"}},{"cell_type":"markdown","source":"## 3.3 Aumento de datos\nPara evitar el problema de sobreajuste, necesitamos expandir artificialmente nuestro conjunto de datos de dígitos escritos a mano. Podemos hacer que su conjunto de datos existente sea aún más grande. La idea es alterar los datos de entrenamiento con pequeñas transformaciones para reproducir las variaciones que ocurren cuando alguien está escribiendo un dígito.\n\nPor ejemplo, el número no está centrado.\nLa escala no es la misma (algunos que escriben con números grandes/pequeños)\nLa imagen está girada...\n\nLos enfoques que alteran los datos de entrenamiento de manera que cambian la representación de la matriz mientras mantienen la etiqueta igual se conocen como técnicas de aumento de datos. Algunos aumentos populares que la gente usa son las escalas de grises, los giros horizontales, los giros verticales, los recortes aleatorios, los cambios de color, las traslaciones, las rotaciones y mucho más.\n\nAl aplicar solo un par de estas transformaciones a nuestros datos de entrenamiento, podemos duplicar o triplicar fácilmente la cantidad de ejemplos de entrenamiento y crear un modelo muy sólido.\n\nLa mejora es importante:\n    - Sin aumento de datos obtuve una precisión del 98.114%\n    - Con el aumento de datos logré un 99,67 % de precisión","metadata":{"_uuid":"9e498b91419439f0fa791e595f202d9a0d56ad6b","_cell_guid":"e2d41e30-0724-40fb-a901-750e514ba9f9"}},{"cell_type":"code","source":"# Sin aumento de datos obtuve una precisión de 0.98114\n#history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs,\n# validación_datos = (X_val, Y_val), detallado = 2)","metadata":{"_execution_state":"idle","_uuid":"d4e9e1ade3c04f9ca4d8cd44e799f9e09524d5a1","_cell_guid":"ade93d2d-90c6-4401-af95-f7d65f8c0a20"},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Con aumento de datos para evitar el sobreajuste (precisión 0.99286)\n\ndatagen = ImageDataGenerator(\n         featurewise_center=False, # establece la media de entrada en 0 sobre el conjunto de datos\n         samplewise_center=False, # establecer la media de cada muestra en 0\n         featurewise_std_normalization=False, # divide las entradas por el estándar del conjunto de datos\n         samplewise_std_normalization=False, # dividir cada entrada por su estándar\n         zca_whitening=False, # aplicar blanqueamiento ZCA\n         rotación_rango=10, # rotar aleatoriamente las imágenes en el rango (grados, 0 a 180)\n         zoom_range = 0.1, # Ampliar imagen aleatoriamente\n         width_shift_range=0.1, # cambiar aleatoriamente las imágenes horizontalmente (fracción del ancho total)\n         height_shift_range=0.1, # cambia aleatoriamente las imágenes verticalmente (fracción de la altura total)\n         horizontal_flip=False, # voltear imágenes aleatoriamente\n         vertical_flip=False) # voltear imágenes aleatoriamente\n\n\ndatagen.fit(X_train)","metadata":{"_execution_state":"idle","_uuid":"21d6192c87d92d497c797656474bccd9cefc5647","_cell_guid":"b342befe-1a6f-44bf-8dab-28033a729122","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"Para el aumento de datos, elegí:\n    - Rota aleatoriamente algunas imágenes de entrenamiento 10 grados\n    - Zoom aleatorio en un 10% algunas imágenes de entrenamiento\n    - Cambia aleatoriamente las imágenes horizontalmente en un 10% del ancho\n    - Cambia aleatoriamente las imágenes verticalmente en un 10% de la altura\n   \nNo apliqué un flip_vertical ni un flip_horizontal ya que podría haber llevado a clasificar erróneamente números simétricos como 6 y 9.\n\nUna vez que nuestro modelo está listo, ajustamos el conjunto de datos de entrenamiento.","metadata":{"_uuid":"51f16d0a5b9d9373438474e7defa7348359d7c18","_cell_guid":"22f80b8a-d4f6-4a34-b33d-ff7334f45d94"}},{"cell_type":"code","source":"# Ajustar el modelo\nhistory = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n                              epochs = epochs, validation_data = (X_val,Y_val),\n                              verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n                              , callbacks=[learning_rate_reduction])","metadata":{"_execution_state":"idle","_uuid":"cf36b3d029f95b553be02d612e097a9769ee8252","_cell_guid":"b453af8d-9736-43e3-b486-7a1cd7dd8909"},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# 4. Evaluar el modelo\n## 4.1 Curvas de entrenamiento y validación","metadata":{"_uuid":"0a1834f2a9f2db15dcaba4a84004b9627d714469","_cell_guid":"e758621d-b27b-40ff-a93f-bebd2e0e5243"}},{"cell_type":"code","source":"# Trazar las curvas de pérdida y precisión para entrenamiento y validación\nfig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['acc'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_acc'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"_execution_state":"idle","_uuid":"3a831860dd5bb65c8ead1ddcf4ae18ae20dd7f3e","_cell_guid":"eb4b1b73-cbd4-40e8-9790-066fcef4c4c0","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"El siguiente código es para trazar curvas de pérdida y precisión para entrenamiento y validación. Desde entonces, configuré epochs = 2 en este portátil.\nTe mostraré las curvas de entrenamiento y validación que obtuve del modelo que construí con 30 épocas (2h30)","metadata":{"_uuid":"ba77212f82b781b0e5a4e494897b18c31c5e30a3","_cell_guid":"69df90d7-f2fd-497d-a0b2-57c497a3e645"}},{"cell_type":"markdown","source":"<img src=\"http://img1.imagilive.com/0717/mnist_099671_train_val_loss_acc.png\"></img>\n\nEl modelo alcanza casi el 99% (98,7+%) de precisión en el conjunto de datos de validación después de 2 épocas. La precisión de la validación es mayor que la precisión del entrenamiento casi todo el tiempo durante el entrenamiento. Eso significa que nuestro modelo no se adapta demasiado al conjunto de entrenamiento.\n\nNuestro modelo está muy bien entrenado !!!\n<img src=\"http://img1.imagilive.com/0717/accuracies1de.jpg\"/>","metadata":{"_uuid":"9f2920cbbfb6f1f566fac4afdd4030c75ee5bf66","_cell_guid":"bacff684-79bb-4ede-83c1-ccb7cf92df77"}},{"cell_type":"markdown","source":"","metadata":{"_uuid":"63698d7d51381b33892ce164b0f21930abb3e937","_cell_guid":"de1c65bd-4a88-4351-9f4b-562e72e7e0fd"}},{"cell_type":"markdown","source":"## 4.2 Matriz de confusión\nLa matriz de confusión puede ser muy útil para ver los inconvenientes de su modelo.\n\nTrazo la matriz de confusión de los resultados de la validación.","metadata":{"_uuid":"3306d29b732341663e50866140dc569360701a81","_cell_guid":"5688faa0-b33b-4e92-b125-7fa0b37e7df3"}},{"cell_type":"code","source":"# Mira la matriz de confusión\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n# Predecir los valores del conjunto de datos de validación\nY_pred = modelo.predecir(X_val)\n# Convertir clases de predicciones en vectores calientes\nY_pred_classes = np.argmax(Y_pred,eje = 1)\n# Convierta las observaciones de validación en un vector caliente\nY_true = np.argmax(Y_val,eje = 1)\n# calcular la matriz de confusión\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n# trazar la matriz de confusión\nplot_confusion_matrix(confusion_mtx, classes = range(10)) ","metadata":{"_execution_state":"idle","_uuid":"16e161179bf1b51ba66c39b2cead883f1db3a9c7","_cell_guid":"11361e73-8250-4bf5-a353-b0f8ea83e659"},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"Aquí podemos ver que nuestra CNN funciona muy bien en todos los dígitos con pocos errores considerando el tamaño del conjunto de validación (4 200 imágenes).\n\nSin embargo, parece que nuestra CNN tiene algunos pequeños problemas con los 4 dígitos, están mal clasificados como 9. A veces es muy difícil captar la diferencia entre 4 y 9 cuando las curvas son suaves.","metadata":{"_uuid":"ecb928433299b163ecc1f6c4e66d4ddcf38fe898","_cell_guid":"1b8a5cdc-9122-4e31-b9fa-0f6b57d33fc8"}},{"cell_type":"markdown","source":"Investiguemos por errores.\n\nQuiero ver los errores más importantes. Para ese propósito, necesito obtener la diferencia entre las probabilidades del valor real y las predichas en los resultados.","metadata":{"_execution_state":"idle","_uuid":"afd59cae1115188b77abd3471e5e89790cef80a0","_cell_guid":"ef54d686-6f79-4d96-a5a0-a64657bd742e"}},{"cell_type":"code","source":"# Mostrar algunos resultados de error\n\n# Los errores son la diferencia entre las etiquetas predichas y las etiquetas verdaderas\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_val_errors = X_val[errors]\n\ndef display_errors(errors_index,img_errors,pred_errors, obs_errors):\n    \"\"\" This function shows 6 images with their predicted and real labels\"\"\"\n    n = 0\n    nrows = 2\n    ncols = 3\n    fig, ax = plt.subplots(nrows,ncols,sharex=True,sharey=True)\n    for row in range(nrows):\n        for col in range(ncols):\n            error = errors_index[n]\n            ax[row,col].imshow((img_errors[error]).reshape((28,28)))\n            ax[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_errors[error],obs_errors[error]))\n            n += 1\n\n# Probabilidades de los números predichos incorrectos\nY_pred_errors_prob = np.max(Y_pred_errors, eje = 1)\n\n# Probabilidades pronosticadas de los valores verdaderos en el conjunto de errores\ntrue_prob_errors = np.diagonal(np.take(Y_pred_errors, Y_true_errors, axis=1))\n\n# Diferencia entre la probabilidad de la etiqueta predicha y la etiqueta verdadera\ndelta_pred_true_errors = Y_pred_errors_prob - true_prob_errors\n\n# Lista ordenada de los errores de prueba delta\nsorted_dela_errors = np.argsort(delta_pred_true_errors)\n\n# 6 errores principales\nerrores_más_importantes = sorted_dela_errors[-6:]\n\n# Mostrar los 6 errores principales\ndisplay_errors(most_important_errors, X_val_errors, Y_pred_classes_errors, Y_true_errors)","metadata":{"_execution_state":"idle","_uuid":"e7a3d6449b499a29db224e42e950f21ca1ec4e36","_cell_guid":"7b0f31b8-c18b-4529-b0d8-eb4c31e30bbf","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Los errores más importantes son también los más intrigantes.\n​\nPara esos seis casos, el modelo no es ridículo. Algunos de estos errores también pueden ser cometidos por humanos, especialmente por uno el 9 que está muy cerca de un 4. El último 9 también es muy engañoso, me parece que es un 0.","metadata":{"_execution_state":"idle","_uuid":"afc408bd5545a6a2b2d4e04989890546263cb642","_cell_guid":"d21c4caf-e699-4647-8ef4-e60e868607ae"}},{"cell_type":"code","source":"# predecir resultados\nresults = model.predict(test)\n\n# seleccione el índice con la máxima probabilidad\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","metadata":{"_execution_state":"idle","_uuid":"7f17e7bf0a54a01a52fef2d554780f6bc6580dc6","_cell_guid":"05ff3b9f-c3bb-4cec-a8c2-2c128e8f15b3","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","metadata":{"_execution_state":"idle","_uuid":"369dfaab09240f3f12bcff91953ffd315ab84985","_cell_guid":"b5f1f39f-13b8-439a-8913-0f120e3d47a9","collapsed":true,"jupyter":{"outputs_hidden":true}},"execution_count":23,"outputs":[]}]}